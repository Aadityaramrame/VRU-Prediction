# üß† VRU Detection, Tracking & Forecasting using Transformers

## üìå Overview  
This project presents an **end-to-end pipeline for Vulnerable Road User (VRU) understanding** ‚Äî from detection and tracking to future trajectory prediction.  
It integrates **Deep Learning, Computer Vision, and Sequential Forecasting** to accurately **predict the next (X, Y) positions** of VRUs such as pedestrians, cyclists, and vehicles using **Transformer-based models**.

---

## üö¶ Project Pipeline  

### 1Ô∏è‚É£ Detection ‚Äî *YOLO-based VRU Identification*  
- Multi-camera video input processed using **YOLO (You Only Look Once)** for object detection.  
- Each VRU (pedestrian, cyclist, vehicle) is localized with bounding boxes and class labels.  
- Depth estimation integrated to improve spatial awareness.

### 2Ô∏è‚É£ Tracking ‚Äî *Multi-object Tracking with DeepSORT*  
- Detected VRUs are tracked across frames using **DeepSORT**, which combines motion and appearance features.  
- Each entity is assigned a **unique TRACK_ID** for continuous observation.  
- Tracking results are exported as CSV/Excel logs containing position and motion data.

### 3Ô∏è‚É£ Feature Engineering  
- Using the tracking logs, motion-based features are computed:
  - `delta_X`, `delta_Y` ‚Üí displacement  
  - `speed` ‚Üí velocity magnitude  
  - `direction` ‚Üí movement angle  
  - `delta_time` ‚Üí frame time difference  
  - `confidence` ‚Üí detection reliability  
- These features form the input for trajectory forecasting.  
- Output stored as: `final_features.xlsx`.

### 4Ô∏è‚É£ Forecasting ‚Äî *Transformer-based VRU Trajectory Prediction*  
- A **PyTorch Transformer model** predicts the next `(X, Y)` positions based on the past sequence of movements.  
- The model learns temporal patterns in VRU trajectories, offering robust short-term forecasts even under occlusions or noise.  
- Outputs include:
  - Predicted vs True next positions  
  - Visualization plots comparing trajectories  

---

## ‚öôÔ∏è Technologies Used  

| Category | Libraries / Tools |
|-----------|------------------|
| Detection | YOLOv8 (Ultralytics) |
| Tracking | DeepSORT |
| Feature Engineering | Pandas, NumPy |
| Forecasting | PyTorch (Transformer Encoder) |
| Visualization | Matplotlib, Seaborn |
| Misc | tqdm, OpenCV |

---

## üöÄ How to Run  

### 1Ô∏è‚É£ Install Requirements  
```bash
pip install -r requirements.txt

2Ô∏è‚É£ Run Detection
python detection.py --input video_path --output detections/

3Ô∏è‚É£ Run Tracking
python tracking.py --detections detections/ --output outputs/

4Ô∏è‚É£ Generate Features
python feature_engineering.py

5Ô∏è‚É£ Train Transformer Forecasting Model
python vru_forecasting_transformer.py

üìä Results

Prediction Task: Next (X, Y) position forecasting

True_X	Pred_X	True_Y	Pred_Y
-0.1430	-0.0200	-1.1667	-0.7944
-1.1723	-1.2759	-1.1667	-1.0285
0.7800	0.6092	-2.5331	-1.0167

Loss: ~0.07 (Normalized MSE)

Visualization:

Trajectories of actual vs predicted motion plotted using Matplotlib.

Predicted trajectories closely follow true VRU motion patterns, validating the model‚Äôs learning capability.

üß© Key Highlights

Fully modular pipeline (Detection ‚Üí Tracking ‚Üí Forecasting)

Combines YOLO + DeepSORT + Transformers

Scalable to multi-camera urban scenes

Integrates depth and motion cues for better context

Feature-engineered dataset reusable for other forecasting models (LSTM, CNN-LSTM, GRU)

üîÆ Future Improvements

Multi-step forecasting for longer prediction horizons

Integrate map or lane context (scene semantics)

Deploy real-time system using ONNX or TorchScript

Introduce uncertainty estimation for safer prediction

üë©‚Äçüíª Contributors

Anusri Kadam & Team
B.Tech ‚Äì Project-Based Learning (FinTech & AI Vision Domain)
Supervised by: Faculty, Department of Computer Engineering
